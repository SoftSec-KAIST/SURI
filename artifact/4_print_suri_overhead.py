import argparse, glob, os
from consts import *

ExpTask = namedtuple('ExpTask', ['dataset', 'log_dir', 'bin_name'])

def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument('dataset', type=str, default='setA', help='Select dataset (setA)')
    args = parser.parse_args()

    # Sanitizing arguments
    assert args.dataset in ['setA'], 'Invalid dataset: "%s"'%(args.dataset)

    return args

################################

def prepare_tasks(args, package):
    tasks = []
    for comp in COMPILERS:
        for opt in OPTIMIZATIONS:
            for lopt in LINKERS:
                data_dir = os.path.join(args.dataset, package, comp, '%s_%s' % (opt, lopt))
                log_dir = os.path.join('stat', 'suri_runtime', task.dataset, package, comp, '%s_%s' % (opt, lopt))
                if os.path.exists(data_dir):
                    orig_dir = os.path.join(data_dir, 'original')
                    for target in glob.glob(orig_dir):
                        filename = os.path.basename(target)
                        tasks.append(ExpTask(args.dataset, log_dir, filename))

    return tasks

################################

def is_valid_data(line):
    if 'seconds' not in line:
        return False
    # FIXME: maybe it should be 'total'?
    if line.split(';')[1].split()[1] not in ['total', 'seconds']:
        return False
    return True

def read_time_data(filepath):
    with open(filepath) as f:
        line = f.read().split('\n')[-2]
        if not is_valid_data(line):
            return None

        time = line.split(';')[1].split()[0]
        return int(time)

def get_data(task, package, tool_name):
    log_path = os.path.join(task.log_dir, tool_name, task.bin_name, '%s.txt' % task.bin_name)
    return read_time_data(log_path)

# Collect data generated by 4_get_suri_overhead.py.
def collect(args, package):
    data = {}
    for package in PACKAGES_SPEC:
        tasks = prepare_tasks(args, package)

        num_bins = 0
        overhead = 0.0
        for task in tasks:
            d_original = get_data(task, package, 'original')
            d_suri = get_data(task, package, 'suri')
            if d_original is None or d_suri is None:
                continue

            num_bins += 1
            overhead += (d_suri - d_original) / d_original

        data[package] = num_bins, overhead

    return data

################################

# Report the percentage of average runtime overheads on the overall dataset.
# This will report the number mentioned in Section 1 (0.2% on average) of our
# paper.
def report(data):
    print(FMT_SURI_HEADER % ('', 'suri'))
    print(FMT_LINE)

    total_num_bins = 0
    total_overhead = 0.0
    for package in PACKAGES_SPEC:
        if package not in data:
            continue

        num_bins, overhead = data[package]
        total_num_bins += num_bins
        total_overhead += overhead
        if num_bins > 0:
            avg_overhead = overhead / num_bins * 100
            print(FMT_SURI % (package, num_bins, avg_overhead)) # Report individual data per package

    if total_num_bins > 0:
        print(FMT_LINE)
        total_avg_overhead = total_overhead / total_num_bins * 100
        print(FMT_SURI % ('Total', total_num_bins, total_avg_overhead)) # Report overall data

if __name__ == '__main__':
    args = parse_arguments()
    data = collect(args)
    report(data)
